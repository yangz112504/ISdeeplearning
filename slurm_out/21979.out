/home/zyang/IS/cudaVsCpu.py:122: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  pivot = pivot.applymap(lambda x: f"{x:.3f} ms" if pd.notna(x) else "")
✅ CUDA available: NVIDIA GeForce RTX 3080
Using devices: [device(type='cpu'), device(type='cuda')]
zailuApprox (cpu): 0.418063s
zailuNormal (cpu): 0.511853s
squareplus (cpu): 0.351414s
swish (cpu): 0.096660s
elu (cpu): 0.068662s
hardshrink (cpu): 0.048580s
hardsigmoid (cpu): 0.052052s
hardtanh (cpu): 0.080257s
hardswish (cpu): 0.054401s
leaky_relu (cpu): 0.060703s
logsigmoid (cpu): 0.141413s
prelu (cpu): 0.154194s
relu (cpu): 0.049463s
relu6 (cpu): 0.069206s
rrelu (cpu): 0.187017s
selu (cpu): 0.056655s
celu (cpu): 0.066227s
gelu (cpu): 0.195896s
sigmoid (cpu): 0.057928s
silu (cpu): 0.064704s
mish (cpu): 0.170270s
softplus (cpu): 0.069506s
softshrink (cpu): 0.044409s
softsign (cpu): 0.209435s
tanh (cpu): 0.054135s
tanhshrink (cpu): 0.098246s
threshold (cpu): 0.092577s
glu (cpu): 0.104008s
identity (cpu): 0.001177s
zailuApprox (cuda): 0.809514s
zailuNormal (cuda): 0.686643s
squareplus (cuda): 0.659077s
swish (cuda): 0.234743s
elu (cuda): 0.140304s
hardshrink (cuda): 0.121968s
hardsigmoid (cuda): 0.128312s
hardtanh (cuda): 0.168087s
hardswish (cuda): 0.134251s
leaky_relu (cuda): 0.139145s
logsigmoid (cuda): 0.141277s
prelu (cuda): 0.404592s
relu (cuda): 0.132370s
relu6 (cuda): 0.159380s
rrelu (cuda): 0.193189s
selu (cuda): 0.129871s
celu (cuda): 0.140970s
gelu (cuda): 0.118377s
sigmoid (cuda): 0.117147s
silu (cuda): 0.125317s
mish (cuda): 0.154418s
softplus (cuda): 0.123532s
softshrink (cuda): 0.119128s
softsign (cuda): 0.406224s
tanh (cuda): 0.118951s
tanhshrink (cuda): 0.235475s
threshold (cuda): 0.177704s
glu (cuda): 0.164343s
identity (cuda): 0.001147s

✅ Saved raw benchmark data to activation_benchmarks_raw.csv

=== Formatted Results (ms per 10k runs) ===
device              CPU  GPU (CUDA)
activation                         
identity       1.177 ms    1.147 ms
softshrink    44.409 ms  119.128 ms
hardshrink    48.580 ms  121.968 ms
relu          49.463 ms  132.370 ms
hardsigmoid   52.052 ms  128.312 ms
tanh          54.135 ms  118.951 ms
hardswish     54.401 ms  134.251 ms
selu          56.655 ms  129.871 ms
sigmoid       57.928 ms  117.147 ms
leaky_relu    60.703 ms  139.145 ms
silu          64.704 ms  125.317 ms
celu          66.227 ms  140.970 ms
elu           68.662 ms  140.304 ms
relu6         69.206 ms  159.380 ms
softplus      69.506 ms  123.532 ms
hardtanh      80.257 ms  168.087 ms
threshold     92.577 ms  177.704 ms
swish         96.660 ms  234.743 ms
tanhshrink    98.246 ms  235.475 ms
glu          104.008 ms  164.343 ms
logsigmoid   141.413 ms  141.277 ms
prelu        154.194 ms  404.592 ms
mish         170.270 ms  154.418 ms
rrelu        187.017 ms  193.189 ms
gelu         195.896 ms  118.377 ms
softsign     209.435 ms  406.224 ms
squareplus   351.414 ms  659.077 ms
zailuApprox  418.063 ms  809.514 ms
zailuNormal  511.853 ms  686.643 ms

✅ Saved formatted table to activation_benchmarks_formatted.csv
