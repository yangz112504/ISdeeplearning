/home/zyang/IS/cudaVsCpu.py:165: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  pivot = pivot.applymap(lambda x: f"{x:.3f} ms" if pd.notna(x) else "")
✅ CUDA available: NVIDIA GeForce RTX 3080
Using devices: [device(type='cpu'), device(type='cuda')]
zailuApprox (cpu): 0.397155s
zailuNormal (cpu): 0.367441s
squareplus (cpu): 0.195708s
swish (cpu): 0.199531s
elu (cpu): 0.247782s
hardshrink (cpu): 0.041320s
hardsigmoid (cpu): 0.046766s
hardtanh (cpu): 0.083873s
hardswish (cpu): 0.054115s
leaky_relu (cpu): 0.057042s
logsigmoid (cpu): 0.144761s
prelu (cpu): 0.143937s
relu (cpu): 0.148120s
relu6 (cpu): 0.065198s
rrelu (cpu): 0.181470s
selu (cpu): 0.046348s
celu (cpu): 0.047414s
gelu (cpu): 0.209645s
sigmoid (cpu): 0.055955s
silu (cpu): 0.052822s
mish (cpu): 0.153398s
softplus (cpu): 0.251627s
softshrink (cpu): 0.044827s
softsign (cpu): 0.204216s
tanh (cpu): 0.051376s
tanhshrink (cpu): 0.092392s
threshold (cpu): 0.098551s
glu (cpu): 0.089901s
identity (cpu): 0.001099s
zailuApprox (cuda): 0.762894s
zailuNormal (cuda): 0.507068s
squareplus (cuda): 0.598736s
swish (cuda): 0.603063s
elu (cuda): 0.645055s
hardshrink (cuda): 0.116694s
hardsigmoid (cuda): 0.123240s
hardtanh (cuda): 0.158083s
hardswish (cuda): 0.126551s
leaky_relu (cuda): 0.136779s
logsigmoid (cuda): 0.142120s
prelu (cuda): 0.405537s
relu (cuda): 0.556045s
relu6 (cuda): 0.151841s
rrelu (cuda): 0.186092s
selu (cuda): 0.123044s
celu (cuda): 0.123637s
gelu (cuda): 0.118324s
sigmoid (cuda): 0.114638s
silu (cuda): 0.118685s
mish (cuda): 0.145076s
softplus (cuda): 0.725814s
softshrink (cuda): 0.113408s
softsign (cuda): 0.380569s
tanh (cuda): 0.111824s
tanhshrink (cuda): 0.225528s
threshold (cuda): 0.164521s
glu (cuda): 0.152860s
identity (cuda): 0.001053s

✅ Saved raw benchmark data to activation_benchmarks_raw.csv

=== Formatted Results (ms per 10k runs) ===
device              CPU  GPU (CUDA)
activation                         
identity       1.099 ms    1.053 ms
hardshrink    41.320 ms  116.694 ms
softshrink    44.827 ms  113.408 ms
selu          46.348 ms  123.044 ms
hardsigmoid   46.766 ms  123.240 ms
celu          47.414 ms  123.637 ms
tanh          51.376 ms  111.824 ms
silu          52.822 ms  118.685 ms
hardswish     54.115 ms  126.551 ms
sigmoid       55.955 ms  114.638 ms
leaky_relu    57.042 ms  136.779 ms
relu6         65.198 ms  151.841 ms
hardtanh      83.873 ms  158.083 ms
glu           89.901 ms  152.860 ms
tanhshrink    92.392 ms  225.528 ms
threshold     98.551 ms  164.521 ms
prelu        143.937 ms  405.537 ms
logsigmoid   144.761 ms  142.120 ms
relu         148.120 ms  556.045 ms
mish         153.398 ms  145.076 ms
rrelu        181.470 ms  186.092 ms
squareplus   195.708 ms  598.736 ms
swish        199.531 ms  603.063 ms
softsign     204.216 ms  380.569 ms
gelu         209.645 ms  118.324 ms
elu          247.782 ms  645.055 ms
softplus     251.627 ms  725.814 ms
zailuNormal  367.441 ms  507.068 ms
zailuApprox  397.155 ms  762.894 ms

✅ Saved formatted table to activation_benchmarks_formatted.csv
